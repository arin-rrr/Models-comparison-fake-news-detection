{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a462410-5f67-4d2c-b078-c5879f89df02",
   "metadata": {},
   "source": [
    "# Часть 1 (классические модели машинного обучения)\n",
    "**Название:** Сравнение классических и современных подходов к детекции фейковых новостей\n",
    "\n",
    "**Описание**: Проект направлен на анализ эффективности различных методов машинного обучения для задачи классификации фейковых новостей. В работе сравниваются:\n",
    "- Классические модели (Logistic Regression, Random Forest)\n",
    "- Современная NLP-модель (LSTM)\n",
    "\n",
    "**Цель** — выявить оптимальный подход по точности, скорости работы и интерпретируемости результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4837eedc-e391-425c-9851-8504163304f9",
   "metadata": {},
   "source": [
    "# **1. Загрузка данных и составление датасета**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33af7238-6e19-4354-ad94-186b18df57a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('FakeReal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1ffe1c0-d563-4e7f-8de5-9573bfa2b213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1           1                                                NaN   \n",
       "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "1     Did they post their votes for Hillary already?      1  \n",
       "2   Now, most of the demonstrators gathered last ...      1  \n",
       "3  A dozen politically active pastors came here f...      0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# нам понадобятся только столбцы title и real\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "447799c3-8886-4a24-917e-c1d1cb364c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_title_real = data[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5817853b-c6ef-46dd-ab0a-a4e7e0edadfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61459</th>\n",
       "      <td>Friday at a Boeing manufacturing facility in N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49580</th>\n",
       "      <td>(Reuters) - It could take years to learn how l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49317</th>\n",
       "      <td>Read more: Daily Mail</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14676</th>\n",
       "      <td>EU NATO Secretary General Jens Stoltenberg spe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70845</th>\n",
       "      <td>WASHINGTON (Reuters) - U.S. House Speaker Paul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "61459  Friday at a Boeing manufacturing facility in N...      0\n",
       "49580  (Reuters) - It could take years to learn how l...      0\n",
       "49317                              Read more: Daily Mail      1\n",
       "14676  EU NATO Secretary General Jens Stoltenberg spe...      1\n",
       "70845  WASHINGTON (Reuters) - U.S. House Speaker Paul...      0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_title_real.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e92af-3ef7-434c-b1d7-69187f98d8d4",
   "metadata": {},
   "source": [
    "Посмотрим, являются ли классы сбалансированными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebbfb56f-aeda-4fd8-b6d4-c597822eb60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    37106\n",
       "0    35028\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_title_real['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de42d4-1522-4792-b687-5cb7b960940e",
   "metadata": {},
   "source": [
    "Классы почти одинакового размера -> возьмём по 15000 примеров каждого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d582ca5a-572e-45d1-9d38-48e2e6afae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_real, count_fake = 0, 0\n",
    "temp = []\n",
    "\n",
    "for i in range(len(data_title_real)):\n",
    "    row = data_title_real.iloc[i]\n",
    "    if row['label'] == 1 and count_real < 15000:\n",
    "        temp.append({'news': row['text'], 'real': 1})\n",
    "        count_real += 1\n",
    "    elif row['label'] == 0 and count_fake < 15000:\n",
    "        temp.append({'news':  row['text'], 'real': 0})\n",
    "        count_fake += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9d15351-93e5-49b0-b8ee-fb2f4271bde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It s certainly no secret that Jefferson Beaure...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nNow that the election is over, Donald Trum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASHINGTON  —   President Obama had “an intens...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When will government officials who allowed thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You may have read or heard about the study deb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ELECTION EVE BOMBSHELL : Wikileaks Reveals Ana...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>America s village idiot got her ass handed to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>For the second time in the last ten days, slim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WASHINGTON (Reuters) - U.S. Rep. Kevin Brady o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>American pride and American exceptionalism is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  real\n",
       "0  It s certainly no secret that Jefferson Beaure...     1\n",
       "1    \\nNow that the election is over, Donald Trum...     1\n",
       "2  WASHINGTON  —   President Obama had “an intens...     0\n",
       "3  When will government officials who allowed thi...     1\n",
       "4  You may have read or heard about the study deb...     0\n",
       "5  ELECTION EVE BOMBSHELL : Wikileaks Reveals Ana...     1\n",
       "6  America s village idiot got her ass handed to ...     1\n",
       "7  For the second time in the last ten days, slim...     1\n",
       "8  WASHINGTON (Reuters) - U.S. Rep. Kevin Brady o...     0\n",
       "9  American pride and American exceptionalism is ...     1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(temp)\n",
    "dataset = pd.DataFrame(temp)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb2df1-d25d-49b6-adbf-bf8413ba667f",
   "metadata": {},
   "source": [
    "Проверим, чтобы в итоговом датасете не было пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "765b5589-5f94-48c1-9c76-9f388ccf2bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news    14\n",
       "real     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a31b8e0a-f775-4804-90b5-46b5c8f62bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6279c8d3-375e-4625-aa61-bb772c8f0a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['news'].str.len() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24d4741b-7085-4f33-a2ea-3bbe8859b7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29986"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# датасет немного уменьшился\n",
    "len(dataset['news'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c02dfd9-724c-425a-bf1b-219aedce97dd",
   "metadata": {},
   "source": [
    "**Очищаем текст**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6548a9a3-22f7-4e15-8859-bb6256473a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It s certainly no secret that Jefferson Beaure...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nNow that the election is over, Donald Trum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASHINGTON  —   President Obama had “an intens...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When will government officials who allowed thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You may have read or heard about the study deb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  real\n",
       "0  It s certainly no secret that Jefferson Beaure...     1\n",
       "1    \\nNow that the election is over, Donald Trum...     1\n",
       "2  WASHINGTON  —   President Obama had “an intens...     0\n",
       "3  When will government officials who allowed thi...     1\n",
       "4  You may have read or heard about the study deb...     0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# от Reuters и городов\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4326b16f-336a-4330-a99c-1a6fd079d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_after_dash(text):\n",
    "    parts = str(text).split('-', 1)  # Разделяем по первому вхождению '-'\n",
    "    return parts[1].strip() if len(parts) > 1 else text  # Возвращаем вторую часть или исходный текст, если '-' нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d23456cb-13f1-403b-b8e4-0a24e0e6f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['cleaned_text'] = dataset['news'].apply(extract_after_dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06c5c48f-a534-4479-a6fe-542cf11dba79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>real</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It s certainly no secret that Jefferson Beaure...</td>\n",
       "      <td>1</td>\n",
       "      <td>wing voters. A BBC report from 2012 showed tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nNow that the election is over, Donald Trum...</td>\n",
       "      <td>1</td>\n",
       "      <td>right, as Bannon has bragged. In other words, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASHINGTON  —   President Obama had “an intens...</td>\n",
       "      <td>0</td>\n",
       "      <td>WASHINGTON  —   President Obama had “an intens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When will government officials who allowed thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>year old man is on suspicion of failure to dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You may have read or heard about the study deb...</td>\n",
       "      <td>0</td>\n",
       "      <td>You may have read or heard about the study deb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  real  \\\n",
       "0  It s certainly no secret that Jefferson Beaure...     1   \n",
       "1    \\nNow that the election is over, Donald Trum...     1   \n",
       "2  WASHINGTON  —   President Obama had “an intens...     0   \n",
       "3  When will government officials who allowed thi...     1   \n",
       "4  You may have read or heard about the study deb...     0   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  wing voters. A BBC report from 2012 showed tha...  \n",
       "1  right, as Bannon has bragged. In other words, ...  \n",
       "2  WASHINGTON  —   President Obama had “an intens...  \n",
       "3  year old man is on suspicion of failure to dis...  \n",
       "4  You may have read or heard about the study deb...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "069cf101-c7fc-427a-858a-9ae7752c5b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wing voters. A BBC report from 2012 showed tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>right, as Bannon has bragged. In other words, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASHINGTON  —   President Obama had “an intens...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year old man is on suspicion of failure to dis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You may have read or heard about the study deb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  real\n",
       "0  wing voters. A BBC report from 2012 showed tha...     1\n",
       "1  right, as Bannon has bragged. In other words, ...     1\n",
       "2  WASHINGTON  —   President Obama had “an intens...     0\n",
       "3  year old man is on suspicion of failure to dis...     1\n",
       "4  You may have read or heard about the study deb...     0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[['cleaned_text', 'real']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0dfca9cb-ed9b-48de-b458-f9a4620f1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('full_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d47cbf6-b973-47a2-872c-f724f892f069",
   "metadata": {},
   "source": [
    "# 2. Функции предобработки текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f86841-dbe9-4a64-8aa6-db8cd035efe3",
   "metadata": {},
   "source": [
    "Будем экспериментировать с **4мя способами предобработки**: *никакой предобработки, даление стопслов и спец.символов, стемминг и лемматизация*\n",
    "\n",
    "**Способ векторизации**: *TfIdfVectorizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7bfe7f9c-26ef-40c6-984b-2506d6f85180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\arina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "stop_words = list(set(stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "358479b1-04fb-4b32-837f-2636647ef20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_special(text):\n",
    "  text = text.lower()\n",
    "  tokens = word_tokenize(text)\n",
    "  tokens = [word for word in tokens if word not in stop_words]  # убираем стоп-слова\n",
    "  tokens = word_tokenize(re.sub(r'[^a-zA-Zа-яА-Я ]', '', ' '.join(tokens)))  # убираем спец символы, числа и знаки препинания\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38141fd8-56e4-4c00-8057-4040bd39a98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\arina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\arina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# стемминг\n",
    "def stemming(text):\n",
    "  tokens = stopwords_special(text)\n",
    "  stemmer = nltk.PorterStemmer()  # инициализируем стеммер\n",
    "  stemmed_tokens = [stemmer.stem(token) for token in tokens]  # перебираем токены и применяем алгоритм стемминга\n",
    "\n",
    "  return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ca92a79e-5919-4bdb-a5f5-20e2bf6946e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(text):\n",
    "  tokens = stopwords_special(text)\n",
    "  lemmatizer = nltk.WordNetLemmatizer()\n",
    "  lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "  return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a51ff-045c-4bd1-aa06-c2911b09feb4",
   "metadata": {},
   "source": [
    "# 3. Деление датасета на train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1702deb6-75a1-4b36-a2c2-e67a9e06b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a3015c6c-3f74-407c-ae37-d8f306d66562",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dataset['cleaned_text'].tolist()\n",
    "real = dataset['real'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff25b5f3-ff88-4f86-aae8-e97120970da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(text, real, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d7765-12c6-4db0-88be-2f1f65771a01",
   "metadata": {},
   "source": [
    "# 4. Обучение Logistic Regression и подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8b7ad17-921f-40ff-a2d2-a5784469ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bd36abff-7ed3-4669-a04f-5ff6cddb5106",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_stop = [' '.join(stopwords_special(i)) for i in train_texts]\n",
    "test_texts_stop = [' '.join(stopwords_special(i)) for i in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee4939df-6de2-4b86-a923-531acf3cbef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_stem = [' '.join(stemming(i)) for i in train_texts]\n",
    "test_texts_stem = [' '.join(stemming(i)) for i in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "84703f04-7260-41ad-86cd-d0b718064be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_lemma = [' '.join(lemma(i)) for i in train_texts]\n",
    "test_texts_lemma = [' '.join(lemma(i)) for i in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a757589d-a005-4c0d-8415-f6add1045d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arina\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\arina\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\arina\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\arina\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arina\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arina\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arina\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "for vect in ['tfidfVectorizer', 'countVectorizer']:\n",
    "    for preprocess in ['nothing', 'stopwords', 'stem', 'lemma']:\n",
    "        # for p in [None, 'l1', 'l2']:\n",
    "            for C in [0.01, 0.001, 0.1, 1]:\n",
    "                    if vect == 'tfidfVectorizer':\n",
    "                        vectorizer = TfidfVectorizer()\n",
    "                    else:\n",
    "                        vectorizer = CountVectorizer()\n",
    "                    \n",
    "                    if preprocess == 'nothing':\n",
    "                        X_train = train_texts\n",
    "                        X_test = test_texts\n",
    "                    elif preprocess == 'stopwords':\n",
    "                        X_train = train_texts_stop\n",
    "                        X_test = test_texts_stop\n",
    "                    elif preprocess == 'stem':\n",
    "                        X_train = train_texts_stem\n",
    "                        X_test = test_texts_stem\n",
    "                    elif preprocess == 'lemma':\n",
    "                        X_train = train_texts_lemma\n",
    "                        X_test = test_texts_lemma\n",
    "\n",
    "                    X_train_vect = vectorizer.fit_transform(X_train)\n",
    "                    X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "                    lr = LogisticRegression(C=C)\n",
    "                    lr.fit(X_train_vect, train_labels)\n",
    "\n",
    "                    y_pred = lr.predict(X_test_vect)\n",
    "                    acc = accuracy_score(test_labels, y_pred)\n",
    "                    f1 = f1_score(test_labels, y_pred)\n",
    "                    res.append([vect, preprocess, C, round(acc, 3), round(f1, 3)])\n",
    "                    if len(res) % 5 == 0:\n",
    "                        print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "06d121cd-3efd-4dc0-9d87-c0bf21ed988d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tfidfVectorizer', 'nothing', 0.01, 0.832, 0.829],\n",
       " ['tfidfVectorizer', 'nothing', 0.001, 0.799, 0.794],\n",
       " ['tfidfVectorizer', 'nothing', 0.1, 0.88, 0.88],\n",
       " ['tfidfVectorizer', 'nothing', 1, 0.925, 0.925],\n",
       " ['tfidfVectorizer', 'stopwords', 0.01, 0.855, 0.859]]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "19c63e64-f110-476e-ab2f-d1f46fab344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_lr = pd.DataFrame(res, columns=[\"Vectorizer\", \"Preprocess\", \"C\", \"accuracy\", \"f1 score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b8d3e515-128e-48de-8ade-07271323c764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Preprocess</th>\n",
       "      <th>C</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>countVectorizer</td>\n",
       "      <td>nothing</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>countVectorizer</td>\n",
       "      <td>nothing</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>countVectorizer</td>\n",
       "      <td>nothing</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>countVectorizer</td>\n",
       "      <td>lemma</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>countVectorizer</td>\n",
       "      <td>stopwords</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Vectorizer Preprocess     C  accuracy  f1 score\n",
       "18  countVectorizer    nothing  0.10     0.934     0.934\n",
       "19  countVectorizer    nothing  1.00     0.934     0.933\n",
       "16  countVectorizer    nothing  0.01     0.930     0.930\n",
       "30  countVectorizer      lemma  0.10     0.929     0.929\n",
       "22  countVectorizer  stopwords  0.10     0.929     0.929"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_lr_sort_f1 = res_lr.sort_values(\"f1 score\", ascending=False)\n",
    "res_lr_sort_f1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e963b5-73ef-4b9f-889b-2dcc943f65af",
   "metadata": {},
   "source": [
    "**Лучшие гиперпараметры для обучения LogisticRegression:**\n",
    "- Vectorizer: countVectorizer\n",
    "- Preprocess: nothing\n",
    "- C = 0.1\n",
    "- accuracy = 0.934\n",
    "- **f1_score = 0.934**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03fd6b8-8e83-4540-867e-654dd6edde83",
   "metadata": {},
   "source": [
    "# 5. Обучение Random Forest (параметры - дефолтные, кроме n_estimatoros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bce2b133-dd71-4919-aec9-2ee8f5db683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6cd7d945-a878-4820-ba72-4f601114c106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "for vect in ['tfidfVectorizer', 'countVectorizer']:\n",
    "    for preprocess in ['nothing', 'stopwords', 'stem', 'lemma']:\n",
    "        for n in [100, 500]:\n",
    "            for m_d in [None, 5, 15, 25]:\n",
    "                        # for c in ['gini', 'entropy']:\n",
    "                            # for c_weight in [None, 'balanced']:\n",
    "                                if vect == 'tfidfVectorizer':\n",
    "                                    vectorizer = TfidfVectorizer()\n",
    "                                else:\n",
    "                                    vectorizer = CountVectorizer()\n",
    "\n",
    "                                if preprocess == 'nothing':\n",
    "                                    X_train = train_texts\n",
    "                                    X_test = test_texts\n",
    "                                elif preprocess == 'stopwords':\n",
    "                                    X_train = train_texts_stop\n",
    "                                    X_test = test_texts_stop\n",
    "                                elif preprocess == 'stem':\n",
    "                                    X_train = train_texts_stem\n",
    "                                    X_test = test_texts_stem\n",
    "                                elif preprocess == 'lemma':\n",
    "                                    X_train = train_texts_lemma\n",
    "                                    X_test = test_texts_lemma\n",
    "\n",
    "                                X_train_vect = vectorizer.fit_transform(X_train)\n",
    "                                X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "                                rf = RandomForestClassifier(n_estimators=n, max_depth=m_d)\n",
    "                                rf.fit(X_train_vect, train_labels)\n",
    "\n",
    "                                y_pred = rf.predict(X_test_vect)\n",
    "                                acc = accuracy_score(test_labels, y_pred)\n",
    "                                f1 = f1_score(test_labels, y_pred)\n",
    "                                res.append([vect, preprocess, n, m_d, round(acc, 3), round(f1, 3)])\n",
    "                                if len(res) % 5 == 0:\n",
    "                                    print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7bce8f2a-89f5-4069-b66a-ef9bc1697b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tfidfVectorizer', 'nothing', 100, None, 0.901, 0.899],\n",
       " ['tfidfVectorizer', 'nothing', 100, 5, 0.794, 0.799],\n",
       " ['tfidfVectorizer', 'nothing', 100, 15, 0.859, 0.859],\n",
       " ['tfidfVectorizer', 'nothing', 100, 25, 0.886, 0.885],\n",
       " ['tfidfVectorizer', 'nothing', 500, None, 0.903, 0.902]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c1529437-d1fc-4d05-ae42-6a78cfbdd0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rf = pd.DataFrame(res, columns=[\"Vectorizer\", \"Preprocess\", \"n_estimators\", \"max_depth\", \"accuracy\", \"f1 score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8e5976a1-11f5-4118-970a-b00b1f96d141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Preprocess</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tfidfVectorizer</td>\n",
       "      <td>stopwords</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>countVectorizer</td>\n",
       "      <td>nothing</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tfidfVectorizer</td>\n",
       "      <td>lemma</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidfVectorizer</td>\n",
       "      <td>nothing</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>countVectorizer</td>\n",
       "      <td>stopwords</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Vectorizer Preprocess  n_estimators  max_depth  accuracy  f1 score\n",
       "12  tfidfVectorizer  stopwords           500        NaN     0.909     0.906\n",
       "36  countVectorizer    nothing           500        NaN     0.909     0.906\n",
       "28  tfidfVectorizer      lemma           500        NaN     0.907     0.904\n",
       "4   tfidfVectorizer    nothing           500        NaN     0.903     0.902\n",
       "44  countVectorizer  stopwords           500        NaN     0.906     0.901"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf_sort_f1 = res_rf.sort_values(\"f1 score\", ascending=False)\n",
    "res_rf_sort_f1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d8727-2c2b-4c7d-8b19-599ef873dfe7",
   "metadata": {},
   "source": [
    "**Лучшие гиперпараметры для обучения RandomForest:**\n",
    "- Vectorizer: countVectorizer\n",
    "- Preprocess: nothing\n",
    "- n_estimators = 500\n",
    "- max_depth = None\n",
    "- accuracy = 0.91\n",
    "- **f1_score = 0.906**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47142895-ea61-4b6b-9cde-5b840704c607",
   "metadata": {},
   "source": [
    "**Лучший результат из классических моделей ML - Logistic Regression (f1-score = 0.934)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
